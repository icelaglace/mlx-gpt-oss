[project]
name = "mlx-gpt-oss"
version = "1.0.0"
description = "Minimal OpenAI-compatible server for GPT-OSS models on Apple Silicon with MLX"
readme = {file = "README.md", content-type = "text/markdown"}
requires-python = ">=3.11"
license = "MIT"
authors = [
  {name = "Hayssam Keilany"},
]
keywords = [
  "gpt-oss",
  "harmony",
  "mlx",
  "fastapi",
  "openai-compatible",
  "minimal",
  "mlx-lm",
]
classifiers = [
  "Development Status :: 5 - Production/Stable",
  "Intended Audience :: Developers",
  "Operating System :: MacOS :: MacOS X",
  "Programming Language :: Python :: 3",
  "Programming Language :: Python :: 3.11",
  "Programming Language :: Python :: 3.12",
  "Topic :: Internet :: WWW/HTTP :: WSGI :: Application",
  "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
license-files = ["LICEN[CS]E*"]

dependencies = [
  "fastapi>=0.115,<1",
  "mlx-lm>=0.30,<1",
  "openai-harmony>=0.0.8,<1",
  "loguru>=0.7,<1",
  "pydantic>=2,<3",
  "uvicorn>=0.35,<1",
]

[project.scripts]
mlx-gpt-oss = "server:main"

[project.urls]
Homepage = "https://github.com/icelaglace/mlx-gpt-oss"
Repository = "https://github.com/icelaglace/mlx-gpt-oss"
Issues = "https://github.com/icelaglace/mlx-gpt-oss/issues"

[project.optional-dependencies]
dev = [
  "build>=1.2,<2",
  "httpx>=0.27,<1",
  "pytest>=8,<10",
  "twine>=5,<7",
]


[build-system]
requires = ["setuptools>=77.0.3", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
py-modules = ["server", "harmony", "schemas"]
